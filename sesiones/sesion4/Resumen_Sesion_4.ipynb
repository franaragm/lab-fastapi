{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìö RESUMEN SESI√ìN 4: Testing e Integraci√≥n con IA Generativa\n",
                "\n",
                "**Prop√≥sito:** Cheat-sheet ejecutable con tablas de referencia r√°pida y snippets reutilizables.\n",
                "\n",
                "**Contenido:**\n",
                "- üß™ Testing con TestClient\n",
                "- ü§ñ Integraci√≥n con OpenAI\n",
                "- üîê Rate Limiting\n",
                "- üîÑ Retry Logic\n",
                "- üìä Tablas de referencia"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalaci√≥n r√°pida de dependencias\n",
                "!pip install fastapi uvicorn[standard] pytest httpx openai python-dotenv -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üß™ TESTING CON TESTCLIENT\n",
                "\n",
                "### Snippet 1: Test b√°sico GET"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fastapi import FastAPI\n",
                "from fastapi.testclient import TestClient\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "@app.get(\"/items/{item_id}\")\n",
                "def read_item(item_id: int):\n",
                "    return {\"item_id\": item_id, \"name\": \"Laptop\"}\n",
                "\n",
                "# Crear cliente de testing\n",
                "client = TestClient(app)\n",
                "\n",
                "# Hacer request\n",
                "response = client.get(\"/items/1\")\n",
                "\n",
                "# Asserts\n",
                "assert response.status_code == 200\n",
                "assert response.json()[\"name\"] == \"Laptop\"\n",
                "\n",
                "print(\"‚úÖ Test GET b√°sico: OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 2: Test POST con validaci√≥n Pydantic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic import BaseModel\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "class Item(BaseModel):\n",
                "    name: str\n",
                "    price: float\n",
                "\n",
                "@app.post(\"/items\", status_code=201)\n",
                "def create_item(item: Item):\n",
                "    return {\"created\": item.dict()}\n",
                "\n",
                "client = TestClient(app)\n",
                "\n",
                "# Test exitoso\n",
                "response_ok = client.post(\"/items\", json={\"name\": \"Mouse\", \"price\": 25.0})\n",
                "assert response_ok.status_code == 201\n",
                "\n",
                "# Test con campo faltante (debe retornar 422)\n",
                "response_error = client.post(\"/items\", json={\"price\": 25.0})\n",
                "assert response_error.status_code == 422\n",
                "\n",
                "print(\"‚úÖ Test POST: OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 3: Fixture reutilizable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_test_client():\n",
                "    \"\"\"Fixture que retorna cliente configurado\"\"\"\n",
                "    app = FastAPI()\n",
                "    \n",
                "    @app.get(\"/health\")\n",
                "    def health():\n",
                "        return {\"status\": \"ok\"}\n",
                "    \n",
                "    return TestClient(app)\n",
                "\n",
                "# Usar en m√∫ltiples tests\n",
                "def test_health():\n",
                "    client = get_test_client()\n",
                "    response = client.get(\"/health\")\n",
                "    assert response.status_code == 200\n",
                "\n",
                "test_health()\n",
                "print(\"‚úÖ Fixture reutilizable: OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 4: Mock de dependencia"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fastapi import Depends, HTTPException\n",
                "from typing import Annotated\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "# Dependencia real (simula auth)\n",
                "def get_current_user():\n",
                "    raise HTTPException(401, \"No autenticado\")\n",
                "\n",
                "CurrentUser = Annotated[dict, Depends(get_current_user)]\n",
                "\n",
                "@app.get(\"/profile\")\n",
                "def get_profile(user: CurrentUser):\n",
                "    return {\"username\": user[\"username\"]}\n",
                "\n",
                "# Mock\n",
                "def mock_user():\n",
                "    return {\"username\": \"testuser\"}\n",
                "\n",
                "# Reemplazar dependencia\n",
                "app.dependency_overrides[get_current_user] = mock_user\n",
                "\n",
                "client = TestClient(app)\n",
                "response = client.get(\"/profile\")\n",
                "assert response.status_code == 200\n",
                "assert response.json()[\"username\"] == \"testuser\"\n",
                "\n",
                "# Limpiar override\n",
                "app.dependency_overrides = {}\n",
                "\n",
                "print(\"‚úÖ Mock de dependencia: OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Status Codes Comunes\n",
                "\n",
                "| C√≥digo | Significado | Cu√°ndo usar |\n",
                "|--------|-------------|-------------|\n",
                "| 200 | OK | GET, PUT, PATCH exitoso |\n",
                "| 201 | Created | POST que crea recurso |\n",
                "| 400 | Bad Request | Error de validaci√≥n de negocio |\n",
                "| 401 | Unauthorized | Falta autenticaci√≥n |\n",
                "| 403 | Forbidden | Usuario autenticado pero sin permisos |\n",
                "| 404 | Not Found | Recurso no existe |\n",
                "| 422 | Unprocessable Entity | Error de validaci√≥n Pydantic |\n",
                "| 429 | Too Many Requests | Rate limit excedido |\n",
                "| 500 | Internal Server Error | Error del servidor |\n",
                "| 503 | Service Unavailable | Servicio temporalmente no disponible |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ü§ñ INTEGRACI√ìN CON OPENAI\n",
                "\n",
                "### Snippet 5: Llamada b√°sica a OpenAI (async)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "from openai import AsyncOpenAI\n",
                "\n",
                "async def llamar_openai(prompt: str, max_tokens: int = 100):\n",
                "    \"\"\"Llamada as√≠ncrona a OpenAI\"\"\"\n",
                "    client = AsyncOpenAI(api_key=\"sk-...\")  # Usar variable de entorno # api_key=os.getenv(\"OPENAI_API_KEY\")\n",
                "    \n",
                "    response = await client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=[\n",
                "            {\"role\": \"system\", \"content\": \"Eres un asistente √∫til\"},\n",
                "            {\"role\": \"user\", \"content\": prompt}\n",
                "        ],\n",
                "        max_tokens=max_tokens,\n",
                "        temperature=0.7\n",
                "    )\n",
                "    \n",
                "    return response\n",
                "\n",
                "# Ejemplo de uso\n",
                "# response = await llamar_openai(\"Explica FastAPI en una l√≠nea\")\n",
                "# texto = response.choices[0].message.content\n",
                "# tokens = response.usage.total_tokens\n",
                "\n",
                "print(\"‚úÖ Snippet OpenAI async: Listo para usar\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 6: Endpoint FastAPI con IA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app = FastAPI()\n",
                "\n",
                "class PromptRequest(BaseModel):\n",
                "    prompt: str\n",
                "    max_tokens: int = 100\n",
                "\n",
                "class PromptResponse(BaseModel):\n",
                "    respuesta: str\n",
                "    tokens_usados: int\n",
                "\n",
                "@app.post(\"/ai/completar\", response_model=PromptResponse)\n",
                "async def completar(request: PromptRequest):\n",
                "    # response = await llamar_openai(request.prompt, request.max_tokens)\n",
                "    \n",
                "    # Simular respuesta para el ejemplo\n",
                "    return PromptResponse(\n",
                "        respuesta=f\"Respuesta simulada a: {request.prompt}\",\n",
                "        tokens_usados=30\n",
                "    )\n",
                "\n",
                "print(\"‚úÖ Endpoint con IA: Listo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Roles de Mensajes OpenAI\n",
                "\n",
                "| Role | Prop√≥sito | Ejemplo |\n",
                "|------|-----------|----------|\n",
                "| system | Instrucciones globales del asistente | \"Eres un experto en Python\" |\n",
                "| user | Mensaje del usuario | \"¬øQu√© es FastAPI?\" |\n",
                "| assistant | Respuesta previa del asistente (para contexto) | \"FastAPI es un framework...\" |\n",
                "\n",
                "### üìä Tabla: Par√°metros Clave\n",
                "\n",
                "| Par√°metro | Rango | Descripci√≥n |\n",
                "|-----------|-------|-------------|\n",
                "| temperature | 0-2 | Creatividad (0=determinista, 2=muy creativo) |\n",
                "| max_tokens | 1-‚àû | L√≠mite de tokens en respuesta |\n",
                "| top_p | 0-1 | Alternativa a temperature (nucleus sampling) |\n",
                "| presence_penalty | -2 a 2 | Penaliza repetici√≥n de temas |\n",
                "| frequency_penalty | -2 a 2 | Penaliza repetici√≥n de palabras |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Tokens y Costes (GPT-3.5-turbo)\n",
                "\n",
                "| Concepto | Valor |\n",
                "|----------|-------|\n",
                "| 1 token | ‚âà 0.75 palabras (ingl√©s) |\n",
                "| 100 tokens | ‚âà 75 palabras |\n",
                "| Coste input | $0.50 / 1M tokens |\n",
                "| Coste output | $1.50 / 1M tokens |\n",
                "| 1K tokens input | $0.0005 |\n",
                "| 1K tokens output | $0.0015 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 7: Calcular coste de una llamada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calcular_coste_gpt35(prompt_tokens: int, completion_tokens: int) -> float:\n",
                "    \"\"\"Calcula coste en USD para GPT-3.5-turbo\"\"\"\n",
                "    coste_input = (prompt_tokens * 0.50) / 1_000_000\n",
                "    coste_output = (completion_tokens * 1.50) / 1_000_000\n",
                "    return coste_input + coste_output\n",
                "\n",
                "# Ejemplo: 500 tokens prompt + 200 tokens completion\n",
                "coste = calcular_coste_gpt35(500, 200)\n",
                "print(f\"Coste: ${coste:.6f} USD\")\n",
                "print(f\"Coste por 1000 llamadas: ${coste * 1000:.2f} USD\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üîê RATE LIMITING\n",
                "\n",
                "### Snippet 8: Rate limiter con ventana deslizante"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import defaultdict\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "rate_limit_store = defaultdict(list)\n",
                "\n",
                "def check_rate_limit(user_id: str, max_requests: int = 10, window_minutes: int = 1) -> bool:\n",
                "    \"\"\"Verifica si el usuario excedi√≥ el l√≠mite\n",
                "    \n",
                "    Args:\n",
                "        user_id: Identificador del usuario\n",
                "        max_requests: N√∫mero m√°ximo de requests\n",
                "        window_minutes: Ventana temporal en minutos\n",
                "    \n",
                "    Returns:\n",
                "        True si puede hacer el request, False si excedi√≥ l√≠mite\n",
                "    \"\"\"\n",
                "    now = datetime.now()\n",
                "    window_start = now - timedelta(minutes=window_minutes)\n",
                "    \n",
                "    # Filtrar requests recientes\n",
                "    recent = [req for req in rate_limit_store[user_id] if req > window_start]\n",
                "    rate_limit_store[user_id] = recent\n",
                "    \n",
                "    # Verificar l√≠mite\n",
                "    if len(recent) >= max_requests:\n",
                "        return False\n",
                "    \n",
                "    # Registrar request actual\n",
                "    rate_limit_store[user_id].append(now)\n",
                "    return True\n",
                "\n",
                "# Ejemplo de uso\n",
                "print(\"Request 1:\", check_rate_limit(\"user123\", max_requests=3))  # True\n",
                "print(\"Request 2:\", check_rate_limit(\"user123\", max_requests=3))  # True\n",
                "print(\"Request 3:\", check_rate_limit(\"user123\", max_requests=3))  # True\n",
                "print(\"Request 4:\", check_rate_limit(\"user123\", max_requests=3))  # False (excedido)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Snippet 9: Endpoint con rate limiting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fastapi import HTTPException\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "@app.post(\"/api/action\")\n",
                "async def action(user_id: str):\n",
                "    # Verificar rate limit\n",
                "    if not check_rate_limit(user_id, max_requests=10):\n",
                "        raise HTTPException(\n",
                "            status_code=429,\n",
                "            detail=\"Rate limit excedido. Intenta en 1 minuto.\"\n",
                "        )\n",
                "    \n",
                "    # Procesar request\n",
                "    return {\"status\": \"ok\"}\n",
                "\n",
                "print(\"‚úÖ Endpoint con rate limiting: Listo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Estrategias de Rate Limiting\n",
                "\n",
                "| Estrategia | Descripci√≥n | Ventajas | Desventajas |\n",
                "|------------|-------------|----------|-------------|\n",
                "| Fixed Window | Contador que resetea cada minuto | Simple | Burst al inicio/fin de ventana |\n",
                "| Sliding Window | Solo cuenta √∫ltimos N segundos | M√°s justo | Requiere almacenar timestamps |\n",
                "| Token Bucket | Tokens se regeneran con el tiempo | Permite bursts controlados | M√°s complejo |\n",
                "| Leaky Bucket | Procesa requests a tasa constante | Suaviza tr√°fico | Puede rechazar requests v√°lidos |\n",
                "\n",
                "#### Nota: En producci√≥n con m√∫ltiples servidores, usar Redis en lugar de un diccionario en memoria para compartir el estado."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üîÑ RETRY LOGIC\n",
                "\n",
                "### Snippet 10: Retry con backoff exponencial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "from fastapi import HTTPException\n",
                "\n",
                "async def llamar_api_con_retry(url: str, max_intentos: int = 3):\n",
                "    \"\"\"Llama a API externa con reintentos y backoff exponencial\n",
                "    \n",
                "    Args:\n",
                "        url: URL de la API\n",
                "        max_intentos: N√∫mero m√°ximo de reintentos\n",
                "    \n",
                "    Returns:\n",
                "        Respuesta de la API\n",
                "    \n",
                "    Raises:\n",
                "        HTTPException 503 si fallan todos los intentos\n",
                "    \"\"\"\n",
                "    for intento in range(max_intentos):\n",
                "        try:\n",
                "            # Intentar llamada\n",
                "            # response = await httpx.AsyncClient().get(url)\n",
                "            # return response.json()\n",
                "            \n",
                "            # Simulaci√≥n\n",
                "            if intento < 2:\n",
                "                raise Exception(\"Error temporal\")\n",
                "            return {\"data\": \"success\"}\n",
                "        \n",
                "        except Exception as e:\n",
                "            espera = 2 ** intento  # 1s, 2s, 4s, 8s...\n",
                "            \n",
                "            if intento < max_intentos - 1:\n",
                "                print(f\"Intento {intento + 1} fall√≥. Esperando {espera}s...\")\n",
                "                await asyncio.sleep(espera)\n",
                "            else:\n",
                "                raise HTTPException(503, \"Servicio no disponible\")\n",
                "\n",
                "# Ejemplo\n",
                "resultado = await llamar_api_con_retry(\"https://api.example.com\")\n",
                "print(f\"‚úÖ Retry exitoso: {resultado}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Comparaci√≥n de Estrategias de Retry\n",
                "\n",
                "| Estrategia | Intento 1 | Intento 2 | Intento 3 | Intento 4 | Total |\n",
                "|------------|-----------|-----------|-----------|-----------|-------|\n",
                "| Sin espera | 0s | 0s | 0s | 0s | 0s |\n",
                "| Espera fija (1s) | 0s | 1s | 2s | 3s | 6s |\n",
                "| Exponencial (2^n) | 0s | 1s | 3s | 7s | 11s |\n",
                "| Fibonacci | 0s | 1s | 2s | 4s | 7s |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Cu√°ndo Usar Retry\n",
                "\n",
                "| Status Code | ¬øReintentar? | Raz√≥n |\n",
                "|-------------|--------------|-------|\n",
                "| 500 | ‚úÖ S√≠ | Error temporal del servidor |\n",
                "| 502 | ‚úÖ S√≠ | Bad gateway (proxy temporalmente ca√≠do) |\n",
                "| 503 | ‚úÖ S√≠ | Service unavailable (sobrecarga temporal) |\n",
                "| 504 | ‚úÖ S√≠ | Gateway timeout |\n",
                "| 429 | ‚úÖ S√≠ | Rate limit (esperar m√°s tiempo) |\n",
                "| 400 | ‚ùå No | Bad request (el request est√° mal) |\n",
                "| 401 | ‚ùå No | Unauthorized (falta auth) |\n",
                "| 403 | ‚ùå No | Forbidden (no tienes permisos) |\n",
                "| 404 | ‚ùå No | Not found (recurso no existe) |\n",
                "| 422 | ‚ùå No | Validaci√≥n fallida (datos incorrectos) |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìä LOGGING Y OBSERVABILIDAD\n",
                "\n",
                "### Snippet 11: Logging estructurado"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import time\n",
                "\n",
                "# Configurar logger\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
                ")\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "@app.post(\"/api/process\")\n",
                "async def process(data: dict, user_id: str = \"anonymous\"):\n",
                "    start_time = time.time()\n",
                "    \n",
                "    # Log del request\n",
                "    logger.info(\n",
                "        f\"[REQUEST] user={user_id} \"\n",
                "        f\"endpoint=/api/process \"\n",
                "        f\"data_size={len(str(data))}\"\n",
                "    )\n",
                "    \n",
                "    # Procesar...\n",
                "    await asyncio.sleep(0.1)  # Simular procesamiento\n",
                "    \n",
                "    # Log del response\n",
                "    duration_ms = int((time.time() - start_time) * 1000)\n",
                "    logger.info(\n",
                "        f\"[RESPONSE] user={user_id} \"\n",
                "        f\"status=200 \"\n",
                "        f\"duration={duration_ms}ms\"\n",
                "    )\n",
                "    \n",
                "    return {\"status\": \"ok\"}\n",
                "\n",
                "print(\"‚úÖ Logging estructurado: Listo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Niveles de Logging\n",
                "\n",
                "| Nivel | Cu√°ndo usar | Ejemplo |\n",
                "|-------|-------------|----------|\n",
                "| DEBUG | Informaci√≥n detallada para debugging | `logger.debug(f\"Variable x={x}\")` |\n",
                "| INFO | Eventos normales importantes | `logger.info(\"Request procesado\")` |\n",
                "| WARNING | Situaciones anormales pero recuperables | `logger.warning(\"Cache miss\")` |\n",
                "| ERROR | Errores que permiten continuar | `logger.error(\"API call failed\")` |\n",
                "| CRITICAL | Errores graves que requieren atenci√≥n | `logger.critical(\"Database down\")` |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üîß PATRONES COMPLETOS\n",
                "\n",
                "### Snippet 12: Endpoint de producci√≥n completo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fastapi import FastAPI, Depends, HTTPException\n",
                "from pydantic import BaseModel\n",
                "import asyncio\n",
                "import time\n",
                "import logging\n",
                "\n",
                "app = FastAPI()\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "class AIRequest(BaseModel):\n",
                "    prompt: str\n",
                "    max_tokens: int = 100\n",
                "\n",
                "def get_current_user():\n",
                "    return {\"user_id\": \"user123\", \"tier\": \"premium\"}\n",
                "\n",
                "@app.post(\"/ai/complete\")\n",
                "async def complete(\n",
                "    request: AIRequest,\n",
                "    user: dict = Depends(get_current_user)\n",
                "):\n",
                "    \"\"\"Endpoint de producci√≥n con todas las mejores pr√°cticas\"\"\"\n",
                "    start_time = time.time()\n",
                "    user_id = user[\"user_id\"]\n",
                "    \n",
                "    # 1. Rate limiting\n",
                "    if not check_rate_limit(user_id, max_requests=10):\n",
                "        logger.warning(f\"[RATE_LIMIT] user={user_id}\")\n",
                "        raise HTTPException(429, \"Rate limit excedido\")\n",
                "    \n",
                "    # 2. Validaci√≥n de negocio\n",
                "    max_allowed = 500 if user[\"tier\"] == \"premium\" else 100\n",
                "    if request.max_tokens > max_allowed:\n",
                "        raise HTTPException(400, f\"max_tokens excede l√≠mite de {max_allowed}\")\n",
                "    \n",
                "    # 3. Log request\n",
                "    logger.info(\n",
                "        f\"[AI_REQUEST] user={user_id} \"\n",
                "        f\"prompt_len={len(request.prompt)} \"\n",
                "        f\"max_tokens={request.max_tokens}\"\n",
                "    )\n",
                "    \n",
                "    # 4. Llamada a IA con retry\n",
                "    # response = await llamar_openai_con_retry(request.prompt, request.max_tokens)\n",
                "    await asyncio.sleep(0.1)  # Simular\n",
                "    \n",
                "    # 5. Calcular m√©tricas\n",
                "    tokens_used = 30\n",
                "    coste = calcular_coste_gpt35(10, 20)\n",
                "    duration_ms = int((time.time() - start_time) * 1000)\n",
                "    \n",
                "    # 6. Log response\n",
                "    logger.info(\n",
                "        f\"[AI_RESPONSE] user={user_id} \"\n",
                "        f\"tokens={tokens_used} \"\n",
                "        f\"coste=${coste:.6f} \"\n",
                "        f\"duration={duration_ms}ms\"\n",
                "    )\n",
                "    \n",
                "    # 7. Retornar con m√©tricas\n",
                "    return {\n",
                "        \"respuesta\": \"Respuesta simulada\",\n",
                "        \"tokens_usados\": tokens_used,\n",
                "        \"coste_estimado\": coste,\n",
                "        \"duracion_ms\": duration_ms\n",
                "    }\n",
                "\n",
                "print(\"‚úÖ Endpoint de producci√≥n: Listo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä Tabla: Checklist de Endpoint de Producci√≥n\n",
                "\n",
                "| Feature | Implementado | Descripci√≥n |\n",
                "|---------|--------------|-------------|\n",
                "| ‚úÖ Auth | S√≠ | Depends(get_current_user) |\n",
                "| ‚úÖ Rate Limiting | S√≠ | check_rate_limit() |\n",
                "| ‚úÖ Validaci√≥n | S√≠ | max_tokens con l√≠mites por tier |\n",
                "| ‚úÖ Logging Request | S√≠ | logger.info() con contexto |\n",
                "| ‚úÖ Logging Response | S√≠ | Incluye tokens, coste, duraci√≥n |\n",
                "| ‚úÖ Retry Logic | S√≠ | Backoff exponencial |\n",
                "| ‚úÖ Error Handling | S√≠ | HTTPException con status correcto |\n",
                "| ‚úÖ M√©tricas | S√≠ | tokens, coste, duraci√≥n |\n",
                "| ‚úÖ Type Hints | S√≠ | Pydantic models |\n",
                "| ‚úÖ Documentaci√≥n | S√≠ | Docstring en endpoint |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéØ MEJORES PR√ÅCTICAS\n",
                "\n",
                "### Testing\n",
                "‚úÖ Usar TestClient para tests r√°pidos sin servidor  \n",
                "‚úÖ Crear fixtures para reutilizar configuraci√≥n  \n",
                "‚úÖ Mockear dependencias externas (DB, APIs, auth)  \n",
                "‚úÖ Testear tanto happy path como casos de error  \n",
                "‚úÖ Limpiar dependency_overrides despu√©s de cada test  \n",
                "\n",
                "### Integraci√≥n con IA\n",
                "‚úÖ Usar async/await para llamadas a APIs externas  \n",
                "‚úÖ Implementar rate limiting (3-10 req/min)  \n",
                "‚úÖ Validar max_tokens antes de llamar (ahorro de $$)  \n",
                "‚úÖ Retry con backoff exponencial (2^n segundos)  \n",
                "‚úÖ Logging estructurado (request + response)  \n",
                "‚úÖ Calcular y trackear m√©tricas (tokens, coste, duraci√≥n)  \n",
                "\n",
                "### Seguridad\n",
                "‚úÖ Autenticaci√≥n en todos los endpoints sensibles  \n",
                "‚úÖ Rate limiting por usuario (no global)  \n",
                "‚úÖ Validaci√≥n de inputs (Pydantic + l√≥gica de negocio)  \n",
                "‚úÖ L√≠mites de recursos (max_tokens, timeout)  \n",
                "‚úÖ Logging de eventos de seguridad (rate limit, auth failures)  \n",
                "\n",
                "### Performance\n",
                "‚úÖ Usar endpoints async cuando hay I/O (DB, APIs)  \n",
                "‚úÖ Implementar caching cuando sea apropiado  \n",
                "‚úÖ Medir duraci√≥n de requests (logger.info con ms)  \n",
                "‚úÖ Optimizar queries a DB (√≠ndices, N+1)  \n",
                "‚úÖ Connection pooling para APIs externas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üö´ ERRORES COMUNES\n",
                "\n",
                "### Testing\n",
                "‚ùå No limpiar `dependency_overrides` ‚Üí Afecta otros tests  \n",
                "‚ùå Usar `response.text` en vez de `response.json()` ‚Üí Error de tipo  \n",
                "‚ùå No verificar status code antes de acceder al JSON ‚Üí Puede fallar  \n",
                "‚ùå Asumir que 422 es error del c√≥digo ‚Üí Es validaci√≥n Pydantic esperada  \n",
                "\n",
                "### Async/Await\n",
                "‚ùå Olvidar `await` ‚Üí Recibir coroutine en vez de resultado  \n",
                "‚ùå Usar `def` en vez de `async def` ‚Üí No poder usar await  \n",
                "‚ùå Usar blocking calls en async ‚Üí Bloquear el event loop  \n",
                "\n",
                "### Rate Limiting\n",
                "‚ùå Reintentar inmediatamente tras 429 ‚Üí Empeorar la situaci√≥n  \n",
                "‚ùå Rate limit global en vez de por usuario ‚Üí Injusto  \n",
                "‚ùå No limpiar timestamps antiguos ‚Üí Memory leak  \n",
                "\n",
                "### Retry Logic\n",
                "‚ùå Reintentar errores 4xx ‚Üí Desperdiciar recursos  \n",
                "‚ùå No usar backoff exponencial ‚Üí Thundering herd  \n",
                "‚ùå Reintentar infinitamente ‚Üí Sistema colgado  \n",
                "\n",
                "### Costes\n",
                "‚ùå No validar max_tokens antes de llamar ‚Üí $$$ desperdiciados  \n",
                "‚ùå No trackear costes ‚Üí Facturas sorpresa  \n",
                "‚ùå Permitir max_tokens ilimitado ‚Üí Vulnerabilidad de $$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üì¶ DEPENDENCIAS NECESARIAS\n",
                "\n",
                "```bash\n",
                "pip install fastapi==0.115.0\n",
                "pip install uvicorn[standard]==0.32.0\n",
                "pip install pytest==8.0.0\n",
                "pip install httpx==0.27.0\n",
                "pip install openai==1.12.0\n",
                "pip install python-dotenv==1.0.0\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üîó RECURSOS ADICIONALES\n",
                "\n",
                "**Documentaci√≥n Oficial:**\n",
                "- FastAPI Testing: https://fastapi.tiangolo.com/tutorial/testing/\n",
                "- OpenAI API: https://platform.openai.com/docs/api-reference\n",
                "- Pydantic: https://docs.pydantic.dev/\n",
                "\n",
                "**Herramientas de Testing:**\n",
                "- pytest: https://docs.pytest.org/\n",
                "- httpx: https://www.python-httpx.org/\n",
                "\n",
                "**Mejores Pr√°cticas:**\n",
                "- Rate Limiting: https://www.ietf.org/rfc/rfc6585.txt\n",
                "- Retry Logic: https://aws.amazon.com/es/blogs/architecture/exponential-backoff-and-jitter/"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
