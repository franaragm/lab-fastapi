{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EJERCICIOS - SESIÓN 4: Testing e Integración con IA Generativa\n",
        "\n",
        "**Instrucciones:**\n",
        "- Completa los espacios marcados con `# TODO`\n",
        "- Ejecuta las celdas para verificar tu solución\n",
        "- Los `assert` te darán feedback inmediato\n",
        "\n",
        "**Estructura:**\n",
        "- **Ejercicios 1-5:** Testing con pytest y TestClient\n",
        "- **Ejercicios 6-10:** Integración con APIs de IA Generativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalación de dependencias\n",
        "!pip install fastapi==0.115.0 uvicorn[standard]==0.32.0 pytest==8.0.0 httpx==0.27.0 google-generativeai python-dotenv==1.0.0 -q\n",
        "print(\" Dependencias instaladas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#  BLOQUE 1: TESTING (Ejercicios 1-5)\n",
        "\n",
        "## EJERCICIO 1: Test de endpoint GET básico\n",
        "\n",
        "**Contexto:** Aprenderás a crear tests simples que verifican status codes y estructura de respuestas JSON. Es la base de cualquier test de API.\n",
        "\n",
        "**Objetivo:** Testear un endpoint GET que retorna información de un producto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API simple con endpoint de producto\n",
        "from fastapi import FastAPI\n",
        "from fastapi import HTTPException\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "app_ej1 = FastAPI()\n",
        "\n",
        "@app_ej1.get(\"/productos/{producto_id}\")\n",
        "def obtener_producto(producto_id: int):\n",
        "    if producto_id == 1:\n",
        "        return {\"id\": 1, \"nombre\": \"Laptop\", \"precio\": 999.99}\n",
        "    elif producto_id == 2:\n",
        "        return {\"id\": 2, \"nombre\": \"Mouse\", \"precio\": 25.50}\n",
        "    else:\n",
        "        raise HTTPException(status_code=404, detail=\"Producto no encontrado\")\n",
        "\n",
        "# TODO: Crea un TestClient para app_ej1\n",
        "client = None  # Reemplaza con TestClient(app_ej1)\n",
        "\n",
        "# TODO: Haz un GET a /productos/1 y verifica:\n",
        "# 1. Status code es 200\n",
        "# 2. El JSON tiene la clave \"nombre\"\n",
        "# 3. El nombre del producto es \"Laptop\"\n",
        "\n",
        "response = None  # TODO: client.get(\"/productos/1\")\n",
        "\n",
        "# TODO: Descomenta y completa los asserts\n",
        "# assert response.status_code == ???\n",
        "# data = response.json()\n",
        "# assert \"nombre\" in data\n",
        "# assert data[\"nombre\"] == ???\n",
        "\n",
        "print(\" Ejercicio 1 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 2: Test de POST con validación Pydantic\n",
        "\n",
        "**Contexto:** Los endpoints POST requieren validar datos de entrada. Pydantic retorna 422 cuando los datos son inválidos. Necesitas saber testear tanto casos exitosos (201) como errores de validación (422).\n",
        "\n",
        "**Objetivo:** Testear un endpoint POST que crea productos, verificando validación Pydantic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "app_ej2 = FastAPI()\n",
        "\n",
        "class ProductoCrear(BaseModel):\n",
        "    nombre: str\n",
        "    precio: float\n",
        "    stock: int = 0\n",
        "\n",
        "@app_ej2.post(\"/productos\", status_code=201)\n",
        "def crear_producto(producto: ProductoCrear):\n",
        "    return {\"mensaje\": \"Producto creado\", \"producto\": producto.dict()}\n",
        "\n",
        "client_ej2 = TestClient(app_ej2)\n",
        "\n",
        "# TODO: Test 1 - POST exitoso con datos completos\n",
        "# Envía JSON: {\"nombre\": \"Teclado\", \"precio\": 49.99, \"stock\": 10}\n",
        "# Verifica que el status code es 201\n",
        "\n",
        "response_exitoso = None  # TODO: client_ej2.post(...)\n",
        "\n",
        "# TODO: assert response_exitoso.status_code == ???\n",
        "\n",
        "# TODO: Test 2 - POST sin campo obligatorio (nombre)\n",
        "# Envía JSON: {\"precio\": 29.99}\n",
        "# Verifica que el status code es 422 (error de validación)\n",
        "\n",
        "response_error = None  # TODO: client_ej2.post(...)\n",
        "\n",
        "# TODO: assert response_error.status_code == ???\n",
        "\n",
        "# TODO: Test 3 - Verificar estructura del error 422\n",
        "# El JSON de error tiene una clave \"detail\" que es una lista\n",
        "\n",
        "# TODO: error_detail = response_error.json()[\"detail\"]\n",
        "# TODO: assert len(error_detail) > 0\n",
        "# TODO: assert error_detail[0][\"type\"] == \"missing\"\n",
        "\n",
        "print(\" Ejercicio 2 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 3: Fixture de cliente de testing\n",
        "\n",
        "**Contexto:** Crear un TestClient en cada test es repetitivo. Las fixtures (funciones reutilizables) evitan duplicación de código y hacen los tests más limpios.\n",
        "\n",
        "**Objetivo:** Crear una función que actúe como fixture, retornando un cliente configurado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Completa la función get_client_fixture()\n",
        "from fastapi import FastAPI\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "def get_client_fixture():\n",
        "    \"\"\"Fixture que retorna un TestClient configurado\"\"\"\n",
        "    app = FastAPI()\n",
        "    \n",
        "    # TODO: Define un endpoint GET /salud que retorne {\"status\": \"ok\"}\n",
        "    @app.get(\"/salud\")\n",
        "    def endpoint_salud():\n",
        "        pass  # TODO: Retorna el diccionario\n",
        "    \n",
        "    # TODO: Define un endpoint GET /usuarios que retorne una lista con 2 usuarios\n",
        "    # Ejemplo: [{\"id\": 1, \"nombre\": \"Ana\"}, {\"id\": 2, \"nombre\": \"Juan\"}]\n",
        "    @app.get(\"/usuarios\")\n",
        "    def listar_usuarios():\n",
        "        pass  # TODO: Retorna la lista\n",
        "    \n",
        "    # TODO: Retorna TestClient(app)\n",
        "    return None\n",
        "\n",
        "# Test 1: Usar fixture para testear /salud\n",
        "def test_salud():\n",
        "    client = get_client_fixture()\n",
        "    response = client.get(\"/salud\")\n",
        "    \n",
        "    # TODO: Verifica que status_code == 200\n",
        "    # TODO: Verifica que el JSON es {\"status\": \"ok\"}\n",
        "    pass\n",
        "\n",
        "# Test 2: Usar fixture para testear /usuarios\n",
        "def test_listar_usuarios():\n",
        "    client = get_client_fixture()\n",
        "    response = client.get(\"/usuarios\")\n",
        "    \n",
        "    # TODO: Verifica que status_code == 200\n",
        "    # TODO: Verifica que la lista tiene 2 elementos\n",
        "    # TODO: Verifica que el primer usuario tiene nombre \"Ana\"\n",
        "    pass\n",
        "\n",
        "test_salud()\n",
        "test_listar_usuarios()\n",
        "print(\" Ejercicio 3 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 4: Mockear dependencia de autenticación\n",
        "\n",
        "**Contexto:** En producción, los endpoints protegidos validan tokens JWT. En tests, no queremos generar tokens reales. Usamos `app.dependency_overrides` para reemplazar la dependencia de auth con un mock que retorna un usuario fake.\n",
        "\n",
        "**Objetivo:** Mockear una dependencia de autenticación para testear un endpoint protegido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import Depends\n",
        "from fastapi import FastAPI\n",
        "from fastapi import HTTPException\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "from typing import Annotated\n",
        "app_ej4 = FastAPI()\n",
        "\n",
        "class Usuario(BaseModel):\n",
        "    username: str\n",
        "    email: str\n",
        "\n",
        "# Dependencia real (simula validar JWT)\n",
        "def get_current_user() -> Usuario:\n",
        "    # En producción: decodifica JWT, valida, busca en BD...\n",
        "    raise HTTPException(status_code=401, detail=\"No autenticado\")\n",
        "\n",
        "CurrentUser = Annotated[Usuario, Depends(get_current_user)]\n",
        "\n",
        "@app_ej4.get(\"/mi-perfil\")\n",
        "def obtener_perfil(usuario: CurrentUser):\n",
        "    return {\"username\": usuario.username, \"email\": usuario.email}\n",
        "\n",
        "# TODO: Crea una función mock_get_current_user() que retorne\n",
        "# un Usuario con username=\"testuser\" y email=\"test@example.com\"\n",
        "def mock_get_current_user() -> Usuario:\n",
        "    pass  # TODO: return Usuario(...)\n",
        "\n",
        "client_ej4 = TestClient(app_ej4)\n",
        "\n",
        "# Test 1: Sin mock, el endpoint debe retornar 401\n",
        "response_sin_mock = client_ej4.get(\"/mi-perfil\")\n",
        "# TODO: assert response_sin_mock.status_code == 401\n",
        "\n",
        "# Test 2: Con mock, el endpoint debe retornar 200\n",
        "# TODO: Reemplaza la dependencia con app_ej4.dependency_overrides\n",
        "# app_ej4.dependency_overrides[get_current_user] = ???\n",
        "\n",
        "response_con_mock = client_ej4.get(\"/mi-perfil\")\n",
        "# TODO: assert response_con_mock.status_code == 200\n",
        "# TODO: Verifica que el JSON tiene \"username\": \"testuser\"\n",
        "\n",
        "# IMPORTANTE: Limpia el override\n",
        "app_ej4.dependency_overrides = {}\n",
        "\n",
        "print(\" Ejercicio 4 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 5: Test de flujo completo (Login + Endpoint protegido)\n",
        "\n",
        "**Contexto:** En aplicaciones reales, los usuarios primero hacen login (obtienen token) y luego acceden a endpoints protegidos con ese token. Necesitas testear este flujo completo de autenticación.\n",
        "\n",
        "**Objetivo:** Testear un sistema con login y endpoint protegido, usando el token obtenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi import HTTPException\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "app_ej5 = FastAPI()\n",
        "\n",
        "# Base de datos fake\n",
        "USUARIOS_DB = {\n",
        "    \"admin\": {\"username\": \"admin\", \"password\": \"secret123\", \"email\": \"admin@example.com\"}\n",
        "}\n",
        "\n",
        "class LoginRequest(BaseModel):\n",
        "    username: str\n",
        "    password: str\n",
        "\n",
        "@app_ej5.post(\"/login\")\n",
        "def login(request: LoginRequest):\n",
        "    user = USUARIOS_DB.get(request.username)\n",
        "    if not user or user[\"password\"] != request.password:\n",
        "        raise HTTPException(status_code=401, detail=\"Credenciales inválidas\")\n",
        "    \n",
        "    # En producción: generar JWT real\n",
        "    token = f\"fake_token_for_{request.username}\"\n",
        "    return {\"access_token\": token, \"token_type\": \"bearer\"}\n",
        "\n",
        "@app_ej5.get(\"/datos-privados\")\n",
        "def datos_privados(token: str = None):\n",
        "    # Validación simple del token (en producción: decodificar JWT)\n",
        "    if not token or not token.startswith(\"fake_token_for_\"):\n",
        "        raise HTTPException(status_code=401, detail=\"Token inválido\")\n",
        "    \n",
        "    username = token.replace(\"fake_token_for_\", \"\")\n",
        "    return {\"mensaje\": f\"Datos privados para {username}\"}\n",
        "\n",
        "client_ej5 = TestClient(app_ej5)\n",
        "\n",
        "# TODO: Test del flujo completo\n",
        "# Paso 1: Hacer login con credenciales correctas\n",
        "response_login = None  # TODO: client_ej5.post(\"/login\", json={...})\n",
        "\n",
        "# TODO: Verifica que login retorna 200\n",
        "# TODO: Obtén el token del JSON: token = response_login.json()[\"access_token\"]\n",
        "\n",
        "# Paso 2: Acceder a endpoint protegido con el token\n",
        "# Pasa el token como query param: ?token=...\n",
        "response_protegido = None  # TODO: client_ej5.get(f\"/datos-privados?token={token}\")\n",
        "\n",
        "# TODO: Verifica que retorna 200\n",
        "# TODO: Verifica que el mensaje contiene \"admin\"\n",
        "\n",
        "# Paso 3: Intentar acceder SIN token (debe fallar)\n",
        "response_sin_token = None  # TODO: client_ej5.get(\"/datos-privados\")\n",
        "\n",
        "# TODO: Verifica que retorna 401\n",
        "\n",
        "print(\" Ejercicio 5 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#  BLOQUE 2: INTEGRACIÓN CON IA GENERATIVA (Ejercicios 6-10)\n",
        "\n",
        "## EJERCICIO 6: Llamada básica a API de IA\n",
        "\n",
        "**Contexto:** Las APIs de IA (Google Gemini, Anthropic) reciben mensajes y retornan una respuesta. Aprenderás la estructura básica de una llamada: mensajes (system, user), parámetros (model, max_tokens), y cómo extraer la respuesta.\n",
        "\n",
        "**Objetivo:** Completar una función que simula una llamada a Google Gemini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "\n",
        "# Mock de respuesta de Gemini (para tests sin API key real)\n",
        "class MockGeminiResponse:\n",
        "    def __init__(self, content, prompt_tokens=10):\n",
        "        self.text = content\n",
        "        self.usage_metadata = type('obj', (object,), {\n",
        "            'prompt_token_count': prompt_tokens,\n",
        "            'candidates_token_count': len(content.split()),\n",
        "            'total_token_count': prompt_tokens + len(content.split())\n",
        "        })\n",
        "\n",
        "# TODO: Completa la funcion llamar_ia()\n",
        "async def llamar_ia(prompt: str):\n",
        "    \"\"\"Simula llamada a Gemini (asincrona)\"\"\"\n",
        "    \n",
        "    # Simulacion de latencia de red\n",
        "    await asyncio.sleep(0.1)\n",
        "    \n",
        "    # Simulacion de respuesta\n",
        "    respuesta_texto = f\"Respuesta simulada a: '{prompt}'\"\n",
        "    \n",
        "    # TODO: Retorna MockGeminiResponse(respuesta_texto, prompt_tokens=10)\n",
        "    return None\n",
        "\n",
        "# Test de la funcion\n",
        "response = await llamar_ia(\"Que es FastAPI?\")\n",
        "\n",
        "# TODO: Verifica que response.text contiene \"FastAPI\"\n",
        "# TODO: Verifica que response.usage_metadata.total_token_count > 0\n",
        "\n",
        "print(\"Ejercicio 6 completado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 7: Endpoint POST /completar con prompt\n",
        "\n",
        "**Contexto:** En aplicaciones reales, expones la funcionalidad de IA a través de endpoints. Los usuarios envían un prompt y reciben una respuesta. Necesitas validar la entrada con Pydantic y retornar datos estructurados.\n",
        "\n",
        "**Objetivo:** Crear un endpoint que recibe un prompt y retorna la respuesta de la IA.\n",
        "\n",
        " **Nota:** Este ejercicio usa la función `llamar_ia()` del Ejercicio 6. Si reinicias el kernel, ejecuta primero el Ejercicio 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "app_ej7 = FastAPI()\n",
        "\n",
        "# TODO: Define modelo Pydantic CompletionRequest con:\n",
        "# - prompt: str\n",
        "# - max_tokens: int = 100\n",
        "class CompletionRequest(BaseModel):\n",
        "    pass  # TODO\n",
        "\n",
        "# TODO: Define modelo CompletionResponse con:\n",
        "# - respuesta: str\n",
        "# - tokens_usados: int\n",
        "class CompletionResponse(BaseModel):\n",
        "    pass  # TODO\n",
        "\n",
        "# TODO: Crea endpoint POST /completar que:\n",
        "# 1. Recibe CompletionRequest\n",
        "# 2. Llama a await llamar_ia(request.prompt, request.max_tokens)\n",
        "# 3. Retorna CompletionResponse con la respuesta y tokens usados\n",
        "@app_ej7.post(\"/completar\", response_model=CompletionResponse)\n",
        "async def completar(request: CompletionRequest):\n",
        "    pass  # TODO\n",
        "\n",
        "client_ej7 = TestClient(app_ej7)\n",
        "\n",
        "# Test del endpoint\n",
        "response = client_ej7.post(\"/completar\", json={\n",
        "    \"prompt\": \"Explica Python\",\n",
        "    \"max_tokens\": 50\n",
        "})\n",
        "\n",
        "# TODO: Verifica status_code == 200\n",
        "# TODO: Verifica que el JSON tiene las claves \"respuesta\" y \"tokens_usados\"\n",
        "# TODO: Verifica que tokens_usados == 30\n",
        "\n",
        "print(\" Ejercicio 7 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 8: Control de max_tokens\n",
        "\n",
        "**Contexto:** Los tokens tienen coste. Necesitas limitar cuántos tokens puede solicitar un usuario para evitar gastos excesivos. Implementarás validación de negocio (max_tokens <= 500) que retorna 400 Bad Request si se excede.\n",
        "\n",
        "**Objetivo:** Añadir validación de max_tokens a un endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi import HTTPException\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "from pydantic import BaseModel\n",
        "app_ej8 = FastAPI()\n",
        "\n",
        "class IARequest(BaseModel):\n",
        "    prompt: str\n",
        "    max_tokens: int = 100\n",
        "\n",
        "# TODO: Crea endpoint POST /completar-seguro que:\n",
        "# 1. Valide que max_tokens <= 500\n",
        "# 2. Si excede, lanza HTTPException(status_code=400, detail=\"max_tokens excede límite de 500\")\n",
        "# 3. Si no excede, llama a await llamar_ia() y retorna la respuesta\n",
        "@app_ej8.post(\"/completar-seguro\")\n",
        "async def completar_seguro(request: IARequest):\n",
        "    # TODO: Validación\n",
        "    pass\n",
        "    \n",
        "    # TODO: Llamada a IA\n",
        "    pass\n",
        "    \n",
        "    # TODO: Retornar respuesta\n",
        "    pass\n",
        "\n",
        "client_ej8 = TestClient(app_ej8)\n",
        "\n",
        "# Test 1: max_tokens dentro del límite (100)\n",
        "response_ok = client_ej8.post(\"/completar-seguro\", json={\n",
        "    \"prompt\": \"Test\",\n",
        "    \"max_tokens\": 100\n",
        "})\n",
        "\n",
        "# TODO: Verifica que retorna 200\n",
        "\n",
        "# Test 2: max_tokens excede el límite (1000)\n",
        "response_error = client_ej8.post(\"/completar-seguro\", json={\n",
        "    \"prompt\": \"Test\",\n",
        "    \"max_tokens\": 1000\n",
        "})\n",
        "\n",
        "# TODO: Verifica que retorna 400\n",
        "# TODO: Verifica que el mensaje de error menciona \"excede límite\"\n",
        "\n",
        "print(\" Ejercicio 8 completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 9: Manejo de errores y timeouts\n",
        "\n",
        "**Contexto:** Las llamadas a APIs externas pueden fallar (timeout, error 500, rate limit). Necesitas implementar retry logic con backoff exponencial: si falla, esperas 1s y reintentas, luego 2s, luego 4s... hasta un máximo de intentos.\n",
        "\n",
        "**Objetivo:** Implementar llamada a IA con reintentos automáticos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from fastapi import FastAPI\n",
        "\n",
        "# Mock de respuesta de Gemini (para tests sin API key real)\n",
        "class MockGeminiResponse:\n",
        "    def __init__(self, content, prompt_tokens=10):\n",
        "        self.text = content\n",
        "        self.usage_metadata = type('obj', (object,), {\n",
        "            'prompt_token_count': prompt_tokens,\n",
        "            'candidates_token_count': len(content.split()),\n",
        "            'total_token_count': prompt_tokens + len(content.split())\n",
        "        })\n",
        "\n",
        "# TODO: Completa la funcion llamar_ia()\n",
        "async def llamar_ia(prompt: str):\n",
        "    \"\"\"Simula llamada a Gemini (asincrona)\"\"\"\n",
        "    \n",
        "    # Simulacion de latencia de red\n",
        "    await asyncio.sleep(0.1)\n",
        "    \n",
        "    # Simulacion de respuesta\n",
        "    respuesta_texto = f\"Respuesta simulada a: '{prompt}'\"\n",
        "    \n",
        "    # TODO: Retorna MockGeminiResponse(respuesta_texto, prompt_tokens=10)\n",
        "    return None\n",
        "\n",
        "# Test de la funcion\n",
        "response = await llamar_ia(\"Que es FastAPI?\")\n",
        "\n",
        "# TODO: Verifica que response.text contiene \"FastAPI\"\n",
        "# TODO: Verifica que response.usage_metadata.total_token_count > 0\n",
        "\n",
        "print(\"Ejercicio 6 completado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## EJERCICIO 10: Sistema completo - Auth + IA + Rate limiting + Logging\n",
        "\n",
        "**Contexto:** Este ejercicio integra todo lo aprendido: autenticación mockeada, llamada a IA, rate limiting (máximo 3 requests por usuario), logging estructurado, y cálculo de costes. Es el tipo de endpoint que irías a producción.\n",
        "\n",
        "**Objetivo:** Construir un endpoint de IA con todas las protecciones y mejores prácticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import Depends\n",
        "from fastapi import FastAPI\n",
        "from fastapi import HTTPException\n",
        "from fastapi import status\n",
        "from fastapi.testclient import TestClient\n",
        "app_ej10 = FastAPI()\n",
        "\n",
        "# Rate limiting store\n",
        "rate_limit_store = defaultdict(list)\n",
        "\n",
        "#  FUNCIÓN YA IMPLEMENTADA (para que te centres en lo importante)\n",
        "def estimar_coste(prompt_tokens: int, completion_tokens: int) -> float:\n",
        "    \"\"\"Calcula coste en USD (Gemini 1.5 Flash: Gratis hasta límite, después $0.075/$0.30 por 1M tokens)\"\"\"\n",
        "    coste_input = (prompt_tokens * 0.50) / 1_000_000\n",
        "    coste_output = (completion_tokens * 1.50) / 1_000_000\n",
        "    return coste_input + coste_output\n",
        "\n",
        "# TODO: Completa check_rate_limit() con las guías\n",
        "def check_rate_limit(user_id: str, max_requests: int = 3) -> bool:\n",
        "    \"\"\"Verifica si el usuario excedió el límite (ventana de 1 minuto)\"\"\"\n",
        "    now = datetime.now()\n",
        "    window_start = now - timedelta(minutes=1)\n",
        "    \n",
        "    # TODO: Filtra solo los requests DENTRO de la ventana temporal\n",
        "    # Pista: [req for req in rate_limit_store[user_id] if req > window_start]\n",
        "    recent_requests = []  # TODO: Implementa el filtro\n",
        "    \n",
        "    # TODO: Actualiza el store con solo los requests recientes\n",
        "    # rate_limit_store[user_id] = recent_requests\n",
        "    \n",
        "    # TODO: Si hay >= max_requests, retorna False\n",
        "    # if len(recent_requests) >= max_requests:\n",
        "    #     return False\n",
        "    \n",
        "    # TODO: Si no, añade el request actual (now) y retorna True\n",
        "    # rate_limit_store[user_id].append(now)\n",
        "    # return True\n",
        "    \n",
        "    pass  # TODO: Reemplaza con tu código\n",
        "\n",
        "# Dependencia mockeada de auth\n",
        "def mock_get_user():\n",
        "    return {\"user_id\": \"testuser\", \"username\": \"Test User\"}\n",
        "\n",
        "# TODO: Completa el endpoint (descomenta y rellena los espacios)\n",
        "@app_ej10.post(\"/ia/completar\")\n",
        "async def completar_ia(\n",
        "    request: IARequest,\n",
        "    user=Depends(mock_get_user)\n",
        "):\n",
        "    \"\"\"Endpoint completo con auth, rate limit, IA, y logging\"\"\"\n",
        "    start_time = time.time()\n",
        "    user_id = user[\"user_id\"]\n",
        "    \n",
        "    # TODO: 1. Verificar rate limit\n",
        "    # if not check_rate_limit(user_id, max_requests=3):\n",
        "    #     raise HTTPException(status_code=429, detail=\"Rate limit excedido\")\n",
        "    \n",
        "    # TODO: 2. Validar max_tokens\n",
        "    # if request.max_tokens > 500:\n",
        "    #     raise HTTPException(status_code=400, detail=\"max_tokens excede límite\")\n",
        "    \n",
        "    # TODO: 3. Log del request (descomenta)\n",
        "    # logger.info(f\"[IA REQUEST] user={user_id} prompt_len={len(request.prompt)}\")\n",
        "    \n",
        "    # TODO: 4. Llamar a IA (recuerda usar await)\n",
        "    # response = await llamar_ia(request.prompt, request.max_tokens)\n",
        "    \n",
        "    # TODO: 5. Calcular métricas (descomenta)\n",
        "    # tokens_used = response.usage_metadata.total_token_count\n",
        "    # coste = estimar_coste(response.usage_metadata.prompt_token_count, response.usage_metadata.candidates_token_count)\n",
        "    # duracion_ms = int((time.time() - start_time) * 1000)\n",
        "    \n",
        "    # TODO: 6. Log del response (descomenta)\n",
        "    # logger.info(f\"[IA RESPONSE] user={user_id} tokens={tokens_used} coste=${coste:.6f}\")\n",
        "    \n",
        "    # TODO: 7. Retornar diccionario con: respuesta, tokens_usados, coste_estimado, duracion_ms\n",
        "    # return {\n",
        "    #     \"respuesta\": response.text,\n",
        "    #     \"tokens_usados\": tokens_used,\n",
        "    #     \"coste_estimado\": coste,\n",
        "    #     \"duracion_ms\": duracion_ms\n",
        "    # }\n",
        "    \n",
        "    pass  # TODO: Reemplaza con tu código\n",
        "\n",
        "# Tests del sistema completo\n",
        "client_ej10 = TestClient(app_ej10)\n",
        "rate_limit_store.clear()\n",
        "\n",
        "# Test 1: Request normal exitoso\n",
        "response1 = client_ej10.post(\"/ia/completar\", json={\n",
        "    \"prompt\": \"Test 1\",\n",
        "    \"max_tokens\": 50\n",
        "})\n",
        "# TODO: Verifica 200 y que tiene \"respuesta\", \"tokens_usados\", \"coste_estimado\"\n",
        "\n",
        "# Test 2: Exceder max_tokens\n",
        "response2 = client_ej10.post(\"/ia/completar\", json={\n",
        "    \"prompt\": \"Test 2\",\n",
        "    \"max_tokens\": 1000\n",
        "})\n",
        "# TODO: Verifica 400\n",
        "\n",
        "# Test 3: Exceder rate limit (hacer 4 requests)\n",
        "for i in range(4):\n",
        "    response = client_ej10.post(\"/ia/completar\", json={\n",
        "        \"prompt\": f\"Test {i+3}\",\n",
        "        \"max_tokens\": 50\n",
        "    })\n",
        "    if i < 2:\n",
        "        pass  # TODO: Verifica 200 (primeros 2 requests después del test 1)\n",
        "    else:\n",
        "        pass  # TODO: Verifica 429 (rate limit excedido)\n",
        "\n",
        "print(\" Ejercicio 10 completado\")\n",
        "print(\" ¡Felicitaciones! Has completado todos los ejercicios de Testing e IA\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
