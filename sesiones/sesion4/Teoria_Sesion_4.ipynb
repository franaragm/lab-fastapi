{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TEOR√çA - SESI√ìN 4: Testing e Integraci√≥n con IA Generativa\n",
                "\n",
                "**Duraci√≥n:** 180 minutos (3 horas)\n",
                "\n",
                "**Objetivos:**\n",
                "- Implementar tests automatizados con pytest y TestClient\n",
                "- Mockear dependencias y autenticaci√≥n en tests\n",
                "- Integrar APIs de IA generativa en FastAPI\n",
                "- Controlar tokens, costes y rate limiting\n",
                "- Manejar errores y timeouts en llamadas a IA"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## CONFIGURACI√ìN DEL ENTORNO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalaci√≥n de dependencias\n",
                "!pip install fastapi==0.115.0 uvicorn[standard]==0.32.0 pytest==8.0.0 httpx==0.27.0 openai==1.12.0 python-dotenv==1.0.0 -q\n",
                "print(\"‚úÖ Dependencias instaladas\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports necesarios\n",
                "from fastapi import FastAPI, Depends, HTTPException, status\n",
                "from fastapi.testclient import TestClient\n",
                "from pydantic import BaseModel\n",
                "from typing import Annotated, Optional\n",
                "import pytest\n",
                "import os\n",
                "from datetime import datetime\n",
                "import time\n",
                "\n",
                "print(\"‚úÖ Imports completados\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# üß™ BLOQUE 1: TESTING (90 minutos)\n",
                "\n",
                "## 1. INTRODUCCI√ìN AL TESTING (10 min)\n",
                "\n",
                "### ¬øPor qu√© testear APIs?\n",
                "\n",
                "Los tests automatizados son esenciales en producci√≥n:\n",
                "\n",
                "1. **Detectar bugs antes de desplegar** ‚Üí Evitar errores en producci√≥n\n",
                "2. **Documentaci√≥n viva** ‚Üí Los tests muestran c√≥mo usar la API\n",
                "3. **Refactorizaci√≥n segura** ‚Üí Cambiar c√≥digo sin miedo a romper funcionalidad\n",
                "4. **CI/CD** ‚Üí Integraci√≥n continua con validaci√≥n autom√°tica\n",
                "\n",
                "### TestClient de FastAPI\n",
                "\n",
                "FastAPI incluye `TestClient` basado en `httpx` para hacer requests sin levantar un servidor real.\n",
                "\n",
                "**Ventajas:**\n",
                "- No necesitas `uvicorn` corriendo\n",
                "- Tests r√°pidos (milisegundos)\n",
                "- Aislamiento total (cada test limpio)\n",
                "\n",
                "### Estructura b√°sica con pytest\n",
                "\n",
                "```python\n",
                "# test_api.py\n",
                "from fastapi.testclient import TestClient\n",
                "\n",
                "def test_nombre_descriptivo():\n",
                "    # Arrange (preparar)\n",
                "    client = TestClient(app)\n",
                "    \n",
                "    # Act (actuar)\n",
                "    response = client.get(\"/ruta\")\n",
                "    \n",
                "    # Assert (verificar)\n",
                "    assert response.status_code == 200\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ejemplo b√°sico: API simple con test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API simple\n",
                "app = FastAPI()\n",
                "\n",
                "@app.get(\"/\")\n",
                "def root():\n",
                "    return {\"mensaje\": \"API funcionando\"}\n",
                "\n",
                "@app.get(\"/saludo/{nombre}\")\n",
                "def saludar(nombre: str):\n",
                "    return {\"saludo\": f\"Hola {nombre}\"}\n",
                "\n",
                "# Test con TestClient\n",
                "client = TestClient(app)\n",
                "\n",
                "# Test 1: Endpoint ra√≠z\n",
                "response = client.get(\"/\")\n",
                "assert response.status_code == 200\n",
                "assert response.json() == {\"mensaje\": \"API funcionando\"}\n",
                "print(\"‚úÖ Test 1 pasado: Endpoint ra√≠z funciona\")\n",
                "\n",
                "# Test 2: Endpoint con par√°metro\n",
                "response = client.get(\"/saludo/Ana\")\n",
                "assert response.status_code == 200\n",
                "assert response.json()[\"saludo\"] == \"Hola Ana\"\n",
                "print(\"‚úÖ Test 2 pasado: Saludo personalizado funciona\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. TESTS B√ÅSICOS (10 min + micro-reto)\n",
                "\n",
                "### Status codes\n",
                "\n",
                "Los tests m√°s comunes verifican los c√≥digos HTTP correctos:\n",
                "\n",
                "- **200 OK** ‚Üí GET exitoso\n",
                "- **201 Created** ‚Üí POST crea recurso\n",
                "- **400 Bad Request** ‚Üí Datos inv√°lidos\n",
                "- **401 Unauthorized** ‚Üí Sin autenticaci√≥n\n",
                "- **404 Not Found** ‚Üí Recurso no existe\n",
                "- **422 Unprocessable Entity** ‚Üí Validaci√≥n Pydantic falla"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API con validaci√≥n Pydantic\n",
                "app_validacion = FastAPI()\n",
                "\n",
                "class Item(BaseModel):\n",
                "    nombre: str\n",
                "    precio: float\n",
                "    cantidad: int = 1\n",
                "\n",
                "@app_validacion.post(\"/items\", status_code=201)\n",
                "def crear_item(item: Item):\n",
                "    return {\"item_creado\": item.dict()}\n",
                "\n",
                "# Tests de status codes\n",
                "client_val = TestClient(app_validacion)\n",
                "\n",
                "# Test 1: POST exitoso retorna 201\n",
                "response = client_val.post(\"/items\", json={\"nombre\": \"Laptop\", \"precio\": 999.99})\n",
                "assert response.status_code == 201\n",
                "print(\"‚úÖ Test: POST exitoso retorna 201\")\n",
                "\n",
                "# Test 2: POST con datos inv√°lidos retorna 422\n",
                "response = client_val.post(\"/items\", json={\"nombre\": \"Laptop\"})  # Falta precio (obligatorio)\n",
                "assert response.status_code == 422\n",
                "print(\"‚úÖ Test: Validaci√≥n Pydantic retorna 422\")\n",
                "\n",
                "# Test 3: Verificar estructura de error 422\n",
                "error_detail = response.json()[\"detail\"]\n",
                "assert len(error_detail) > 0  # Hay al menos un error\n",
                "assert error_detail[0][\"type\"] == \"missing\"  # Campo faltante\n",
                "print(\"‚úÖ Test: Error 422 tiene estructura correcta\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validaci√≥n de estructura de respuesta\n",
                "\n",
                "Adem√°s del status code, debemos verificar que el JSON retornado tenga la estructura esperada."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test completo de estructura\n",
                "response = client_val.post(\"/items\", json={\n",
                "    \"nombre\": \"Mouse\",\n",
                "    \"precio\": 25.50,\n",
                "    \"cantidad\": 3\n",
                "})\n",
                "\n",
                "assert response.status_code == 201\n",
                "data = response.json()\n",
                "\n",
                "# Verificar que existe la clave \"item_creado\"\n",
                "assert \"item_creado\" in data\n",
                "\n",
                "# Verificar estructura interna\n",
                "item = data[\"item_creado\"]\n",
                "assert item[\"nombre\"] == \"Mouse\"\n",
                "assert item[\"precio\"] == 25.50\n",
                "assert item[\"cantidad\"] == 3\n",
                "\n",
                "print(\"‚úÖ Test: Estructura de respuesta correcta\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üß™ MICRO-RETO 1: Test de endpoint con error\n",
                "\n",
                "Crea un test que verifique que un endpoint retorna 404 cuando se busca un recurso inexistente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API con endpoint que puede retornar 404\n",
                "app_404 = FastAPI()\n",
                "\n",
                "ITEMS_DB = {\n",
                "    1: {\"nombre\": \"Laptop\", \"precio\": 999.99},\n",
                "    2: {\"nombre\": \"Mouse\", \"precio\": 25.50}\n",
                "}\n",
                "\n",
                "@app_404.get(\"/items/{item_id}\")\n",
                "def obtener_item(item_id: int):\n",
                "    item = ITEMS_DB.get(item_id)\n",
                "    if not item:\n",
                "        raise HTTPException(status_code=404, detail=\"Item no encontrado\")\n",
                "    return item\n",
                "\n",
                "# TODO: Completa el test\n",
                "client_404 = TestClient(app_404)\n",
                "\n",
                "# Test 1: Item existente retorna 200\n",
                "# TODO: Completa aqu√≠\n",
                "\n",
                "# Test 2: Item inexistente retorna 404\n",
                "# TODO: Completa aqu√≠\n",
                "\n",
                "# Test 3: Verificar mensaje de error\n",
                "# TODO: Completa aqu√≠"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. FIXTURES Y MOCKING (15 min + micro-reto)\n",
                "\n",
                "### ¬øQu√© son las fixtures en pytest?\n",
                "\n",
                "Las **fixtures** son funciones reutilizables que preparan el entorno para tests.\n",
                "\n",
                "**Ventajas:**\n",
                "- Evitar c√≥digo duplicado\n",
                "- Setup/teardown autom√°tico\n",
                "- Tests m√°s limpios y legibles\n",
                "\n",
                "**Ejemplo b√°sico:**\n",
                "```python\n",
                "@pytest.fixture\n",
                "def client():\n",
                "    return TestClient(app)\n",
                "\n",
                "def test_endpoint(client):  # pytest inyecta autom√°ticamente\n",
                "    response = client.get(\"/\")\n",
                "    assert response.status_code == 200\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fixture de cliente de testing\n",
                "\n",
                "En notebooks no podemos usar el decorador `@pytest.fixture`, pero podemos simular el concepto con funciones."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulaci√≥n de fixture (en archivo .py usar√≠as @pytest.fixture)\n",
                "def get_test_client():\n",
                "    \"\"\"Retorna un cliente de testing configurado\"\"\"\n",
                "    app = FastAPI()\n",
                "    \n",
                "    @app.get(\"/usuarios\")\n",
                "    def listar_usuarios():\n",
                "        return [{\"id\": 1, \"nombre\": \"Ana\"}, {\"id\": 2, \"nombre\": \"Juan\"}]\n",
                "    \n",
                "    return TestClient(app)\n",
                "\n",
                "# Uso de la fixture\n",
                "def test_listar_usuarios():\n",
                "    client = get_test_client()\n",
                "    response = client.get(\"/usuarios\")\n",
                "    \n",
                "    assert response.status_code == 200\n",
                "    usuarios = response.json()\n",
                "    assert len(usuarios) == 2\n",
                "    assert usuarios[0][\"nombre\"] == \"Ana\"\n",
                "\n",
                "test_listar_usuarios()\n",
                "print(\"‚úÖ Test con fixture pasado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### app.dependency_overrides: Mockear dependencias\n",
                "\n",
                "En tests, a menudo queremos **mockear** (simular) dependencias como autenticaci√≥n, bases de datos, etc.\n",
                "\n",
                "FastAPI tiene `app.dependency_overrides` para reemplazar dependencias en tests.\n",
                "\n",
                "**Caso de uso t√≠pico:** Mockear autenticaci√≥n para no necesitar tokens reales."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API con autenticaci√≥n\n",
                "app_auth = FastAPI()\n",
                "\n",
                "class User(BaseModel):\n",
                "    username: str\n",
                "    email: str\n",
                "\n",
                "# Dependencia real (simula validar token)\n",
                "def get_current_user() -> User:\n",
                "    # En producci√≥n: validar√≠a JWT, buscar√≠a en BD, etc.\n",
                "    raise HTTPException(status_code=401, detail=\"No autenticado\")\n",
                "\n",
                "CurrentUser = Annotated[User, Depends(get_current_user)]\n",
                "\n",
                "@app_auth.get(\"/perfil\")\n",
                "def obtener_perfil(current_user: CurrentUser):\n",
                "    return current_user\n",
                "\n",
                "# SIN MOCK: Endpoint retorna 401\n",
                "client_auth = TestClient(app_auth)\n",
                "response = client_auth.get(\"/perfil\")\n",
                "assert response.status_code == 401\n",
                "print(\"‚úÖ Sin mock: Retorna 401 como esperado\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CON MOCK: Reemplazar dependencia\n",
                "def mock_get_current_user() -> User:\n",
                "    \"\"\"Usuario mockeado para tests\"\"\"\n",
                "    return User(username=\"testuser\", email=\"test@example.com\")\n",
                "\n",
                "# Reemplazar dependencia SOLO en tests\n",
                "app_auth.dependency_overrides[get_current_user] = mock_get_current_user\n",
                "\n",
                "# Ahora el endpoint retorna 200 con usuario mockeado\n",
                "response = client_auth.get(\"/perfil\")\n",
                "assert response.status_code == 200\n",
                "assert response.json()[\"username\"] == \"testuser\"\n",
                "print(\"‚úÖ Con mock: Retorna 200 con usuario mockeado\")\n",
                "\n",
                "# IMPORTANTE: Limpiar despu√©s del test\n",
                "app_auth.dependency_overrides = {}\n",
                "print(\"‚úÖ Override limpiado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Patr√≥n completo: Test con fixture + mock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_test_client_with_mock():\n",
                "    \"\"\"Fixture que retorna cliente con autenticaci√≥n mockeada\"\"\"\n",
                "    app = FastAPI()\n",
                "    \n",
                "    # Dependencia real\n",
                "    def get_user():\n",
                "        raise HTTPException(status_code=401)\n",
                "    \n",
                "    # Mock\n",
                "    def mock_user():\n",
                "        return {\"id\": 1, \"username\": \"testuser\"}\n",
                "    \n",
                "    @app.get(\"/protected\")\n",
                "    def protected_route(user=Depends(get_user)):\n",
                "        return {\"mensaje\": f\"Hola {user['username']}\"}\n",
                "    \n",
                "    # Reemplazar dependencia\n",
                "    app.dependency_overrides[get_user] = mock_user\n",
                "    \n",
                "    return TestClient(app)\n",
                "\n",
                "# Test\n",
                "client = get_test_client_with_mock()\n",
                "response = client.get(\"/protected\")\n",
                "assert response.status_code == 200\n",
                "assert \"testuser\" in response.json()[\"mensaje\"]\n",
                "print(\"‚úÖ Test con fixture + mock completo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üß™ MICRO-RETO 2: Mockear base de datos\n",
                "\n",
                "Crea un test que mockee una funci√≥n de \"buscar en BD\" para retornar datos fake."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_db = FastAPI()\n",
                "\n",
                "# Dependencia que simula consulta a BD\n",
                "def get_db_connection():\n",
                "    # En producci√≥n: retornar√≠a conexi√≥n real a PostgreSQL, etc.\n",
                "    raise Exception(\"BD no disponible en tests\")\n",
                "\n",
                "@app_db.get(\"/productos\")\n",
                "def listar_productos(db=Depends(get_db_connection)):\n",
                "    # En producci√≥n: db.query(...)\n",
                "    return db\n",
                "\n",
                "# TODO: Crea una funci√≥n mock_db que retorne una lista fake de productos\n",
                "def mock_db():\n",
                "    # TODO: Retorna [{\"id\": 1, \"nombre\": \"Laptop\"}, {\"id\": 2, \"nombre\": \"Mouse\"}]\n",
                "    pass\n",
                "\n",
                "# TODO: Reemplaza la dependencia con app_db.dependency_overrides\n",
                "\n",
                "# TODO: Haz un test GET /productos y verifica que retorna la lista fake\n",
                "\n",
                "# TODO: Limpia el override"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# ü§ñ BLOQUE 2: INTEGRACI√ìN CON IA GENERATIVA (90 minutos)\n",
                "\n",
                "## 1. INTEGRACI√ìN CON APIS DE IA (10 min + micro-reto)\n",
                "\n",
                "### Llamada a OpenAI/Anthropic\n",
                "\n",
                "La librer√≠a `openai` (v1+) es compatible con m√∫ltiples proveedores:\n",
                "\n",
                "- **OpenAI** (GPT-4, GPT-3.5)\n",
                "- **Anthropic** (Claude) ‚Üí Compatible con OpenAI SDK\n",
                "- **Otros** (con base_url personalizada)\n",
                "\n",
                "### Configuraci√≥n de API keys\n",
                "\n",
                "**‚ö†Ô∏è IMPORTANTE:** NUNCA hardcodear API keys en el c√≥digo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from openai import OpenAI\n",
                "\n",
                "# ‚úÖ FORMA CORRECTA: Variable de entorno\n",
                "# En terminal: export OPENAI_API_KEY=\"tu-clave\"\n",
                "# O usar archivo .env con python-dotenv\n",
                "\n",
                "# Configuraci√≥n del cliente\n",
                "# Nota: En producci√≥n, estas variables vienen del entorno\n",
                "# Para este notebook educativo, las definimos como None\n",
                "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
                "\n",
                "if not OPENAI_API_KEY:\n",
                "    print(\"‚ö†Ô∏è OPENAI_API_KEY no configurada (normal en notebook educativo)\")\n",
                "    print(\"   En producci√≥n: export OPENAI_API_KEY='tu-clave'\")\n",
                "else:\n",
                "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
                "    print(\"‚úÖ Cliente OpenAI configurado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Estructura b√°sica de request\n",
                "\n",
                "Todas las APIs de LLM siguen un patr√≥n similar:\n",
                "\n",
                "```python\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-3.5-turbo\",\n",
                "    messages=[\n",
                "        {\"role\": \"system\", \"content\": \"Eres un asistente √∫til\"},\n",
                "        {\"role\": \"user\", \"content\": \"¬øQu√© es FastAPI?\"}\n",
                "    ],\n",
                "    max_tokens=100,\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "texto = response.choices[0].message.content\n",
                "```\n",
                "\n",
                "**Par√°metros clave:**\n",
                "- `model`: Modelo a usar (gpt-4, gpt-3.5-turbo, etc.)\n",
                "- `messages`: Lista de mensajes (system, user, assistant)\n",
                "- `max_tokens`: L√≠mite de tokens en respuesta\n",
                "- `temperature`: Creatividad (0 = determinista, 1 = creativo)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ejemplo simulado (sin API key real)\n",
                "\n",
                "Para prop√≥sitos educativos, simularemos la estructura de respuesta:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulaci√≥n de respuesta de OpenAI para fines educativos\n",
                "class MockChoice:\n",
                "    def __init__(self, content):\n",
                "        self.message = type('obj', (object,), {'content': content})\n",
                "\n",
                "class MockResponse:\n",
                "    def __init__(self, content, tokens_used):\n",
                "        self.choices = [MockChoice(content)]\n",
                "        self.usage = type('obj', (object,), {\n",
                "            'prompt_tokens': 10,\n",
                "            'completion_tokens': tokens_used,\n",
                "            'total_tokens': 10 + tokens_used\n",
                "        })\n",
                "\n",
                "def mock_openai_call(messages, max_tokens=100):\n",
                "    \"\"\"Simula llamada a OpenAI\"\"\"\n",
                "    user_msg = messages[-1][\"content\"]\n",
                "    response_text = f\"Esta es una respuesta simulada a: '{user_msg}'\"\n",
                "    return MockResponse(response_text, tokens_used=15)\n",
                "\n",
                "# Ejemplo de uso\n",
                "response = mock_openai_call([\n",
                "    {\"role\": \"system\", \"content\": \"Eres un asistente\"},\n",
                "    {\"role\": \"user\", \"content\": \"¬øQu√© es FastAPI?\"}\n",
                "])\n",
                "\n",
                "print(\"Respuesta:\", response.choices[0].message.content)\n",
                "print(\"Tokens usados:\", response.usage.total_tokens)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Integraci√≥n en endpoint de FastAPI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_ia = FastAPI()\n",
                "\n",
                "class CompletionRequest(BaseModel):\n",
                "    prompt: str\n",
                "    max_tokens: int = 100\n",
                "\n",
                "class CompletionResponse(BaseModel):\n",
                "    respuesta: str\n",
                "    tokens_usados: int\n",
                "\n",
                "@app_ia.post(\"/completar\", response_model=CompletionResponse)\n",
                "async def completar_texto(request: CompletionRequest):\n",
                "    \"\"\"Endpoint que llama a API de IA\"\"\"\n",
                "    \n",
                "    # Simular llamada a OpenAI\n",
                "    response = mock_openai_call(\n",
                "        messages=[{\"role\": \"user\", \"content\": request.prompt}],\n",
                "        max_tokens=request.max_tokens\n",
                "    )\n",
                "    \n",
                "    return CompletionResponse(\n",
                "        respuesta=response.choices[0].message.content,\n",
                "        tokens_usados=response.usage.total_tokens\n",
                "    )\n",
                "\n",
                "# Test\n",
                "client_ia = TestClient(app_ia)\n",
                "response = client_ia.post(\"/completar\", json={\n",
                "    \"prompt\": \"Explica qu√© es FastAPI\",\n",
                "    \"max_tokens\": 50\n",
                "})\n",
                "\n",
                "assert response.status_code == 200\n",
                "data = response.json()\n",
                "print(\"‚úÖ Endpoint de IA funcionando\")\n",
                "print(f\"Respuesta: {data['respuesta'][:50]}...\")\n",
                "print(f\"Tokens: {data['tokens_usados']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üß™ MICRO-RETO 3: Endpoint con prompt personalizado\n",
                "\n",
                "Crea un endpoint `/traducir` que reciba texto y lo \"traduzca\" usando un system prompt espec√≠fico."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Define modelo TraduccionRequest con campos: texto, idioma_destino\n",
                "\n",
                "# TODO: Crea endpoint POST /traducir que:\n",
                "# 1. Use system prompt: \"Eres un traductor profesional\"\n",
                "# 2. User prompt: f\"Traduce al {idioma}: {texto}\"\n",
                "# 3. Llame a mock_openai_call\n",
                "# 4. Retorne la \"traducci√≥n\"\n",
                "\n",
                "# TODO: Test: Solicitar traducir \"Hello\" a \"espa√±ol\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. CONTROL DE TOKENS Y COSTES (10 min + micro-reto)\n",
                "\n",
                "### Token limits\n",
                "\n",
                "Los LLMs tienen l√≠mites de tokens:\n",
                "\n",
                "- **gpt-3.5-turbo**: 4,096 tokens (input + output)\n",
                "- **gpt-4**: 8,192 tokens\n",
                "- **gpt-4-32k**: 32,768 tokens\n",
                "\n",
                "**1 token ‚âà 0.75 palabras en ingl√©s** (m√°s en otros idiomas)\n",
                "\n",
                "### Estimaci√≥n de costes\n",
                "\n",
                "**Precios aproximados (GPT-3.5-turbo):**\n",
                "- Input: $0.50 / 1M tokens\n",
                "- Output: $1.50 / 1M tokens\n",
                "\n",
                "**Ejemplo:**\n",
                "- Request con 100 tokens input + 200 tokens output\n",
                "- Coste: (100 √ó $0.50 + 200 √ó $1.50) / 1,000,000 = $0.00035"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Funci√≥n para estimar costes\n",
                "def estimar_coste(prompt_tokens: int, completion_tokens: int, modelo=\"gpt-3.5-turbo\"):\n",
                "    \"\"\"Estima el coste de una llamada a OpenAI\"\"\"\n",
                "    \n",
                "    # Precios por mill√≥n de tokens (actualizar seg√∫n pricing oficial)\n",
                "    PRECIOS = {\n",
                "        \"gpt-3.5-turbo\": {\"input\": 0.50, \"output\": 1.50},\n",
                "        \"gpt-4\": {\"input\": 30.00, \"output\": 60.00},\n",
                "    }\n",
                "    \n",
                "    precios = PRECIOS.get(modelo, PRECIOS[\"gpt-3.5-turbo\"])\n",
                "    \n",
                "    coste_input = (prompt_tokens * precios[\"input\"]) / 1_000_000\n",
                "    coste_output = (completion_tokens * precios[\"output\"]) / 1_000_000\n",
                "    \n",
                "    return coste_input + coste_output\n",
                "\n",
                "# Ejemplo\n",
                "coste = estimar_coste(prompt_tokens=100, completion_tokens=200)\n",
                "print(f\"Coste estimado: ${coste:.6f}\")\n",
                "print(f\"Coste por 1000 requests: ${coste * 1000:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Rate limiting b√°sico\n",
                "\n",
                "Para controlar costes y evitar abusos, implementamos rate limiting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import defaultdict\n",
                "from datetime import datetime, timedelta\n",
                "\n",
                "# Almac√©n simple de rate limiting (en producci√≥n: usar Redis)\n",
                "rate_limit_store = defaultdict(list)\n",
                "\n",
                "def check_rate_limit(user_id: str, max_requests: int = 10, window_minutes: int = 1) -> bool:\n",
                "    \"\"\"Verifica si el usuario excedi√≥ el l√≠mite de requests\"\"\"\n",
                "    now = datetime.now()\n",
                "    window_start = now - timedelta(minutes=window_minutes)\n",
                "    \n",
                "    # Filtrar requests dentro de la ventana temporal\n",
                "    recent_requests = [\n",
                "        req_time for req_time in rate_limit_store[user_id]\n",
                "        if req_time > window_start\n",
                "    ]\n",
                "    \n",
                "    rate_limit_store[user_id] = recent_requests\n",
                "    \n",
                "    # Verificar l√≠mite\n",
                "    if len(recent_requests) >= max_requests:\n",
                "        return False\n",
                "    \n",
                "    # Registrar nuevo request\n",
                "    rate_limit_store[user_id].append(now)\n",
                "    return True\n",
                "\n",
                "# Ejemplo de uso\n",
                "for i in range(12):\n",
                "    if check_rate_limit(\"user123\", max_requests=10):\n",
                "        print(f\"Request {i+1}: ‚úÖ Permitido\")\n",
                "    else:\n",
                "        print(f\"Request {i+1}: ‚ùå Rate limit excedido\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Integraci√≥n en endpoint con rate limit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_rate = FastAPI()\n",
                "\n",
                "@app_rate.post(\"/completar-limitado\")\n",
                "async def completar_con_rate_limit(request: CompletionRequest, user_id: str = \"default\"):\n",
                "    \"\"\"Endpoint con rate limiting\"\"\"\n",
                "    \n",
                "    # Verificar rate limit\n",
                "    if not check_rate_limit(user_id, max_requests=5, window_minutes=1):\n",
                "        raise HTTPException(\n",
                "            status_code=429,\n",
                "            detail=\"Rate limit excedido. Intenta en 1 minuto.\"\n",
                "        )\n",
                "    \n",
                "    # Llamar a IA\n",
                "    response = mock_openai_call(\n",
                "        messages=[{\"role\": \"user\", \"content\": request.prompt}],\n",
                "        max_tokens=request.max_tokens\n",
                "    )\n",
                "    \n",
                "    return {\n",
                "        \"respuesta\": response.choices[0].message.content,\n",
                "        \"tokens_usados\": response.usage.total_tokens\n",
                "    }\n",
                "\n",
                "# Test: Exceder rate limit\n",
                "client_rate = TestClient(app_rate)\n",
                "rate_limit_store.clear()  # Limpiar contador\n",
                "\n",
                "for i in range(7):\n",
                "    response = client_rate.post(\"/completar-limitado?user_id=test\", json={\n",
                "        \"prompt\": f\"Request {i+1}\"\n",
                "    })\n",
                "    if response.status_code == 200:\n",
                "        print(f\"Request {i+1}: ‚úÖ 200\")\n",
                "    elif response.status_code == 429:\n",
                "        print(f\"Request {i+1}: ‚ö†Ô∏è 429 Rate limit\")\n",
                "        break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üß™ MICRO-RETO 4: Control de max_tokens\n",
                "\n",
                "Modifica el endpoint para rechazar requests con `max_tokens > 500` (c√≥digo 400)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Crea endpoint /completar-seguro que:\n",
                "# 1. Valide que max_tokens <= 500\n",
                "# 2. Si excede, retorne HTTPException 400\n",
                "# 3. Si no, llame a mock_openai_call\n",
                "\n",
                "# TODO: Test 1: max_tokens=100 ‚Üí 200 OK\n",
                "# TODO: Test 2: max_tokens=1000 ‚Üí 400 Bad Request"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. MANEJO DE ERRORES (10 min + micro-reto)\n",
                "\n",
                "### Timeouts largos\n",
                "\n",
                "Las llamadas a APIs de IA pueden tardar varios segundos. Debemos:\n",
                "\n",
                "1. **Configurar timeouts** para evitar requests colgados\n",
                "2. **Informar al usuario** si la operaci√≥n toma mucho tiempo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "\n",
                "async def llamada_ia_con_timeout(prompt: str, timeout_segundos: int = 30):\n",
                "    \"\"\"Llamada a IA con timeout\"\"\"\n",
                "    try:\n",
                "        # Simular llamada que tarda\n",
                "        async def llamada_lenta():\n",
                "            await asyncio.sleep(2)  # Simula latencia\n",
                "            return mock_openai_call([{\"role\": \"user\", \"content\": prompt}])\n",
                "        \n",
                "        # Ejecutar con timeout\n",
                "        response = await asyncio.wait_for(llamada_lenta(), timeout=timeout_segundos)\n",
                "        return response\n",
                "    \n",
                "    except asyncio.TimeoutError:\n",
                "        raise HTTPException(\n",
                "            status_code=504,\n",
                "            detail=f\"Timeout: La IA no respondi√≥ en {timeout_segundos}s\"\n",
                "        )\n",
                "\n",
                "# Test\n",
                "response = await llamada_ia_con_timeout(\"Test\", timeout_segundos=5)\n",
                "print(\"‚úÖ Llamada con timeout exitosa\")\n",
                "print(f\"Respuesta: {response.choices[0].message.content[:50]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retry logic con backoff exponencial\n",
                "\n",
                "Si la API falla temporalmente, podemos reintentar con esperas crecientes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def llamada_ia_con_retry(prompt: str, max_intentos: int = 3):\n",
                "    \"\"\"Llamada con reintentos y backoff exponencial\"\"\"\n",
                "    \n",
                "    for intento in range(max_intentos):\n",
                "        try:\n",
                "            # Simular que falla las primeras 2 veces\n",
                "            if intento < 2:\n",
                "                raise Exception(\"Error temporal de API\")\n",
                "            \n",
                "            response = mock_openai_call([{\"role\": \"user\", \"content\": prompt}])\n",
                "            return response\n",
                "        \n",
                "        except Exception as e:\n",
                "            espera = 2 ** intento  # Backoff exponencial: 1s, 2s, 4s...\n",
                "            print(f\"Intento {intento + 1} fall√≥. Reintentando en {espera}s...\")\n",
                "            \n",
                "            if intento < max_intentos - 1:\n",
                "                await asyncio.sleep(espera)\n",
                "            else:\n",
                "                raise HTTPException(\n",
                "                    status_code=503,\n",
                "                    detail=\"API de IA no disponible tras m√∫ltiples intentos\"\n",
                "                )\n",
                "\n",
                "# Test\n",
                "response = await llamada_ia_con_retry(\"Test retry\")\n",
                "print(\"‚úÖ Retry exitoso\")\n",
                "print(f\"Respuesta: {response.choices[0].message.content[:50]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Logging de uso\n",
                "\n",
                "Es cr√≠tico registrar cada llamada a IA para monitoreo de costes y debugging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "# Configurar logging\n",
                "logging.basicConfig(level=logging.INFO)\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "class IALogger:\n",
                "    \"\"\"Logger especializado para llamadas a IA\"\"\"\n",
                "    \n",
                "    @staticmethod\n",
                "    def log_request(user_id: str, prompt: str, max_tokens: int):\n",
                "        logger.info(f\"[IA REQUEST] user={user_id} prompt_len={len(prompt)} max_tokens={max_tokens}\")\n",
                "    \n",
                "    @staticmethod\n",
                "    def log_response(user_id: str, tokens_used: int, coste: float, duracion_ms: int):\n",
                "        logger.info(\n",
                "            f\"[IA RESPONSE] user={user_id} tokens={tokens_used} \"\n",
                "            f\"coste=${coste:.6f} duracion={duracion_ms}ms\"\n",
                "        )\n",
                "    \n",
                "    @staticmethod\n",
                "    def log_error(user_id: str, error: str):\n",
                "        logger.error(f\"[IA ERROR] user={user_id} error={error}\")\n",
                "\n",
                "# Ejemplo de uso\n",
                "start_time = time.time()\n",
                "\n",
                "IALogger.log_request(\"user123\", \"¬øQu√© es FastAPI?\", max_tokens=100)\n",
                "response = mock_openai_call([{\"role\": \"user\", \"content\": \"Test\"}])\n",
                "\n",
                "duracion_ms = int((time.time() - start_time) * 1000)\n",
                "coste = estimar_coste(10, 15)\n",
                "\n",
                "IALogger.log_response(\"user123\", tokens_used=25, coste=coste, duracion_ms=duracion_ms)\n",
                "print(\"‚úÖ Logging configurado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Endpoint completo con manejo de errores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_completo = FastAPI()\n",
                "\n",
                "@app_completo.post(\"/ia/completar\")\n",
                "async def endpoint_ia_completo(\n",
                "    request: CompletionRequest,\n",
                "    user_id: str = \"default\"\n",
                "):\n",
                "    \"\"\"Endpoint de IA con todas las mejores pr√°cticas\"\"\"\n",
                "    \n",
                "    start_time = time.time()\n",
                "    \n",
                "    try:\n",
                "        # 1. Validar max_tokens\n",
                "        if request.max_tokens > 500:\n",
                "            raise HTTPException(status_code=400, detail=\"max_tokens excede l√≠mite de 500\")\n",
                "        \n",
                "        # 2. Rate limiting\n",
                "        if not check_rate_limit(user_id, max_requests=5):\n",
                "            raise HTTPException(status_code=429, detail=\"Rate limit excedido\")\n",
                "        \n",
                "        # 3. Log request\n",
                "        IALogger.log_request(user_id, request.prompt, request.max_tokens)\n",
                "        \n",
                "        # 4. Llamar a IA con timeout y retry\n",
                "        response = await llamada_ia_con_retry(request.prompt, max_intentos=3)\n",
                "        \n",
                "        # 5. Calcular m√©tricas\n",
                "        tokens_used = response.usage.total_tokens\n",
                "        coste = estimar_coste(response.usage.prompt_tokens, response.usage.completion_tokens)\n",
                "        duracion_ms = int((time.time() - start_time) * 1000)\n",
                "        \n",
                "        # 6. Log response\n",
                "        IALogger.log_response(user_id, tokens_used, coste, duracion_ms)\n",
                "        \n",
                "        # 7. Retornar respuesta\n",
                "        return {\n",
                "            \"respuesta\": response.choices[0].message.content,\n",
                "            \"tokens_usados\": tokens_used,\n",
                "            \"coste_estimado\": coste,\n",
                "            \"duracion_ms\": duracion_ms\n",
                "        }\n",
                "    \n",
                "    except HTTPException:\n",
                "        raise\n",
                "    except Exception as e:\n",
                "        IALogger.log_error(user_id, str(e))\n",
                "        raise HTTPException(status_code=500, detail=\"Error interno al procesar request\")\n",
                "\n",
                "# Test\n",
                "client_completo = TestClient(app_completo)\n",
                "rate_limit_store.clear()\n",
                "\n",
                "response = client_completo.post(\"/ia/completar?user_id=test\", json={\n",
                "    \"prompt\": \"Explica FastAPI en 2 l√≠neas\",\n",
                "    \"max_tokens\": 50\n",
                "})\n",
                "\n",
                "assert response.status_code == 200\n",
                "data = response.json()\n",
                "print(\"\\n‚úÖ Endpoint completo funcionando\")\n",
                "print(f\"Respuesta: {data['respuesta'][:60]}...\")\n",
                "print(f\"Tokens: {data['tokens_usados']}\")\n",
                "print(f\"Coste: ${data['coste_estimado']:.6f}\")\n",
                "print(f\"Duraci√≥n: {data['duracion_ms']}ms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üß™ MICRO-RETO 5: Endpoint con logging completo\n",
                "\n",
                "A√±ade logs INFO cuando el rate limit es excedido (antes de lanzar el 429)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Modifica check_rate_limit() para que haga:\n",
                "# logger.info(f\"[RATE LIMIT] user={user_id} requests={len(recent_requests)}/{max_requests}\")\n",
                "\n",
                "# TODO: Cuando se exceda, loggea ANTES de retornar False:\n",
                "# logger.warning(f\"[RATE LIMIT EXCEEDED] user={user_id}\")\n",
                "\n",
                "# TODO: Test: Haz 6 requests y verifica que aparece el log de warning"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}